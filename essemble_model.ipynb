{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c96576d",
   "metadata": {},
   "source": [
    "# Assemble Model using DenseNet, EfficientNet, ResNet50, XGBoost, Light GBM, and CatBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0552969-dff4-4a3e-9bb9-361925f9e4c4",
   "metadata": {},
   "source": [
    "## Here's datasets you will need\n",
    "- train-image.hdf5\n",
    "- train-metadata.csv\n",
    "- augmented_data.hdf5\n",
    "- augmented_metadata.csv\n",
    "- isic_image.hdf5\n",
    "- isic_metadata.csv\n",
    "- test-image.hdf5\n",
    "- test-metadata.csv\n",
    "## Here's the models/paths you need to run without training the CNN model\n",
    "- DenseNet121_checkpoints/DenseNet121_epoch_20.pth\n",
    "- EfficientNet-B3_checkpoints/EfficientNet-B3_epoch_20.pth\n",
    "- ResNet50_checkpoints/ResNet50_epoch_20.pth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb04e90",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65dd2089",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import torch\n",
    "import cv2\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms, models\n",
    "from torchvision.models import densenet121, DenseNet121_Weights\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from tqdm import tqdm\n",
    "# from dataset import HDF5Dataset\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from isic_metric import score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4863765d",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a0a64a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "labels = []\n",
    "metadata = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a898a1d",
   "metadata": {},
   "source": [
    "### First, load the malignant data from original database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa7f05a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_train_hdf5_path = 'train-image.hdf5'\n",
    "original_train_metadata_path = 'train-metadata.csv'\n",
    "original_train_metadata = pd.read_csv(original_train_metadata_path,low_memory=False)   \n",
    "original_train_hdf5 = h5py.File(original_train_hdf5_path, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31be5557",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 401059/401059 [00:19<00:00, 20927.90it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(original_train_metadata))):\n",
    "    if original_train_metadata.iloc[i]['target'] == 0: # skip non-malignant images\n",
    "        continue\n",
    "    image_id = original_train_metadata.iloc[i]['isic_id']\n",
    "    image = original_train_hdf5[image_id][()]\n",
    "    image = np.frombuffer(image, dtype=np.uint8)\n",
    "    image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
    "    image = cv2.resize(image, (128, 128))\n",
    "    image = image / 255\n",
    "    \n",
    "    images.append(image)\n",
    "    labels.append(1)\n",
    "    metadata.append(original_train_metadata.iloc[i])\n",
    "    \n",
    "# original_train_hdf5.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3c9664",
   "metadata": {},
   "source": [
    "### Second, load the augmented malignant images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45e157a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_malignant_hdf5_path = 'augmented_data.hdf5'\n",
    "augmented_malignant_metadata_path = 'augmented_metadata.csv'\n",
    "augmented_malignant_metadata = pd.read_csv(augmented_malignant_metadata_path,low_memory=False)\n",
    "augmented_malignant_hdf5 = h5py.File(augmented_malignant_hdf5_path, 'r')\n",
    "n_augmentations = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d51fd96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1965/1965 [00:01<00:00, 1023.86it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(augmented_malignant_metadata))):\n",
    "\n",
    "    image_id = f\"{augmented_malignant_metadata.iloc[i]['isic_id']}\"\n",
    "    image = augmented_malignant_hdf5[image_id][()]\n",
    "    image = np.frombuffer(image, dtype=np.uint8)\n",
    "    image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
    "    # show image\n",
    "    # plt.imshow(image)\n",
    "    # plt.axis('off')\n",
    "    # plt.show()\n",
    "    image = cv2.resize(image, (128, 128))\n",
    "    image = image / 255\n",
    "\n",
    "    images.append(image)\n",
    "    labels.append(1)\n",
    "    metadata.append(augmented_malignant_metadata.iloc[i])\n",
    "    \n",
    "augmented_malignant_hdf5.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5be58e",
   "metadata": {},
   "source": [
    "### Third, load the ISIC full database's malignant examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77a82feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "isic_metadata_path = 'isic_metadata.csv'\n",
    "isic_hdf5_path = 'isic_image.hdf5'\n",
    "isic_metadata = pd.read_csv(isic_metadata_path,low_memory=False)\n",
    "isic_hdf5 = h5py.File(isic_hdf5_path, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0569ae99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 81722/81722 [00:24<00:00, 3311.55it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "malignant count: 9239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "malignant_count = 0\n",
    "for i in tqdm(range(len(isic_metadata))):\n",
    "    if isic_metadata.iloc[i]['benign_malignant'] == 'malignant': # skip non-malignant images\n",
    "        image_id = isic_metadata.iloc[i]['isic_id']\n",
    "        image = isic_hdf5[image_id][()]\n",
    "        image = np.frombuffer(image, dtype=np.uint8)\n",
    "        image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
    "        image = cv2.resize(image, (128, 128))\n",
    "        image = image / 255\n",
    "        malignant_count += 1\n",
    "        \n",
    "        images.append(image)\n",
    "        labels.append(1)\n",
    "        metadata.append(isic_metadata.iloc[i])\n",
    "print(f\"malignant count: {malignant_count}\")\n",
    "isic_hdf5.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eef13ace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "malignant count: 11597\n"
     ]
    }
   ],
   "source": [
    "malignant_count = len(labels)\n",
    "print(f\"malignant count: {malignant_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b978ee",
   "metadata": {},
   "source": [
    "### Lastly, load the same amount of beign data from original database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "199f2b2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading benign images: 100%|██████████| 11597/11597 [00:08<00:00, 1424.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "benign count: 11597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "benign_loaded = 0\n",
    "\n",
    "pbar = tqdm(total=malignant_count, desc=\"Loading benign images\")\n",
    "while benign_loaded < malignant_count:\n",
    "    if original_train_metadata.iloc[idx]['target'] == 0:\n",
    "        image_id = original_train_metadata.iloc[idx]['isic_id']\n",
    "        image = original_train_hdf5[image_id][()]\n",
    "        image = np.frombuffer(image, dtype=np.uint8)\n",
    "        image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
    "        image = cv2.resize(image, (128, 128))\n",
    "        image = image / 255\n",
    "        images.append(image)\n",
    "        labels.append(0)\n",
    "        metadata.append(original_train_metadata.iloc[idx])\n",
    "        benign_loaded += 1\n",
    "        pbar.update(1)\n",
    "    idx += 1\n",
    "pbar.close()\n",
    "\n",
    "original_train_hdf5.close()\n",
    "print(f\"benign count: {benign_loaded}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e76c222a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23194\n"
     ]
    }
   ],
   "source": [
    "print(len(images))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188a93fb",
   "metadata": {},
   "source": [
    "### Generate Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a373bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import HDF5Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 70% for training\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    images, labels, test_size=0.3, stratify=labels, random_state=42\n",
    ")\n",
    "\n",
    "# 15% validation, 15% testing\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42\n",
    ")\n",
    "\n",
    "# split metadata\n",
    "metadata_train, metadata_temp = train_test_split(\n",
    "    metadata, test_size=0.3, stratify=labels, random_state=42\n",
    ")\n",
    "metadata_val, metadata_test = train_test_split(\n",
    "    metadata_temp, test_size=0.5, stratify=y_temp, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "385d384e-0605-4008-a2c6-988c0c2ec895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: 16235\n",
      "Validation data: 3479\n",
      "Test data: 3480\n",
      "Metadata Training data: 16235\n",
      "Metadata Validation data: 3479\n",
      "Metadata Test data: 3480\n"
     ]
    }
   ],
   "source": [
    "print(f'Training data: {len(X_train)}')\n",
    "print(f'Validation data: {len(X_val)}')\n",
    "print(f'Test data: {len(X_test)}')\n",
    "print(f'Metadata Training data: {len(metadata_train)}')\n",
    "print(f'Metadata Validation data: {len(metadata_val)}')\n",
    "print(f'Metadata Test data: {len(metadata_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4938933",
   "metadata": {},
   "source": [
    "### Load ISIC Competition Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3dc199a",
   "metadata": {},
   "outputs": [],
   "source": [
    "isic_test_metadata_path = 'test-metadata.csv'\n",
    "isic_test_metadata = pd.read_csv(isic_test_metadata_path,low_memory=False)\n",
    "isic_test_hdf5_path = 'test-image.hdf5'\n",
    "isic_test_hdf5 = h5py.File(isic_test_hdf5_path, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65ba078",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "X_test_isic = []\n",
    "X_test_isic_id = []\n",
    "metadata_test_isic = []\n",
    "for i in tqdm(range(len(isic_test_metadata))):\n",
    "    image_id = isic_test_metadata.iloc[i]['isic_id']\n",
    "    image = isic_test_hdf5[image_id][()]\n",
    "    image = np.frombuffer(image, dtype=np.uint8)\n",
    "    image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
    "    image = cv2.resize(image, (128, 128))\n",
    "    image = image / 255\n",
    "    \n",
    "    # since it does not have labels, we need to manualy ensure it works with the models\n",
    "    if isinstance(image, np.ndarray):\n",
    "        # First ensure it's uint8\n",
    "        if image.dtype != np.uint8:\n",
    "            image = (image * 255).astype(np.uint8)\n",
    "        image = Image.fromarray(image)\n",
    "    X_test_isic.append(image)\n",
    "    metadata_test_isic.append(isic_test_metadata.iloc[i])\n",
    "    X_test_isic_id.append(image_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc78d322",
   "metadata": {},
   "source": [
    "## Load CNN models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c34365c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b756755",
   "metadata": {},
   "source": [
    "### DenseNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dcc2dff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import densenet121, DenseNet121_Weights\n",
    "from ModelTrainer import Trainer\n",
    "densenet_weights = DenseNet121_Weights.DEFAULT\n",
    "densenet_transform = densenet_weights.transforms()\n",
    "densenet_train_dataset = HDF5Dataset(X_train, y_train, augment=True, transform=densenet_transform)\n",
    "densenet_val_dataset = HDF5Dataset(X_val, y_val, augment=False, transform=densenet_transform)\n",
    "densenet_model = densenet121(weights=densenet_weights)\n",
    "lr = 1e-4\n",
    "num_epochs = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c5f922-ec03-40cd-9e78-b4503c025aa4",
   "metadata": {},
   "source": [
    "#### NOTE!! Still need to run this block below if loading weights!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "93bfeb98-614b-4fca-964c-42f354131128",
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_net_trainer = Trainer(device, densenet_train_dataset, densenet_val_dataset, \"DenseNet121\", densenet_weights, densenet_transform, densenet_model, lr, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c247174f-cfff-4084-b71f-f95c879a1818",
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_net_trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea77a71",
   "metadata": {},
   "source": [
    "### Load model if already trained and calculate pAUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad0556c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 1891/3480 [00:29<00:24, 65.58it/s]"
     ]
    }
   ],
   "source": [
    "densenet_model_path = \"DenseNet121_checkpoints/DenseNet121_epoch_20.pth\"\n",
    "densenet_checkpoint = torch.load(densenet_model_path, weights_only=False, map_location=device)\n",
    "densenet_model.load_state_dict(densenet_checkpoint['model_state_dict'])\n",
    "from calc_pauc import pAUC\n",
    "calc_pAUC = pAUC(device, densenet_model, densenet_transform, X_test, y_test,  metadata_test)\n",
    "calc_pAUC.compute_pAUC()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630f6b59",
   "metadata": {},
   "source": [
    "### Calculate test pAUC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cace52ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from calc_pauc import pAUC\n",
    "calc_pAUC = pAUC(device, dense_net_trainer.model, dense_net_trainer.transform, X_test, y_test,  metadata_test)\n",
    "calc_pAUC.compute_pAUC()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe25088-416d-456f-b84d-77a9ca36d32c",
   "metadata": {},
   "source": [
    "## EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4914910f-00ef-48d5-b255-de089719c2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import efficientnet_b3, EfficientNet_B3_Weights\n",
    "efficientnet_weights = EfficientNet_B3_Weights.DEFAULT\n",
    "efficientnet_transform = efficientnet_weights.transforms()\n",
    "efficientnet_train_dataset = HDF5Dataset(X_train, y_train, augment=True, transform=efficientnet_transform)\n",
    "efficientnet_val_dataset = HDF5Dataset(X_val, y_val, augment=False, transform=efficientnet_transform)\n",
    "efficientnet_model = efficientnet_b3(weights=efficientnet_weights)\n",
    "lr = 3e-5\n",
    "num_epochs = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a52a6f-9457-4d1e-8624-d3f59911dff2",
   "metadata": {},
   "source": [
    "### Note: Still need to initialize Trainer!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0bc69c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "efficientnet_trainer = Trainer(device, efficientnet_train_dataset, efficientnet_val_dataset, \"EfficientNet-B3\", efficientnet_weights, efficientnet_transform, efficientnet_model, lr, num_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201a9cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "efficientnet_trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca1ab4b",
   "metadata": {},
   "source": [
    "### Load EfficientNet Model if already trained and compute pAUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad971031",
   "metadata": {},
   "outputs": [],
   "source": [
    "efficientnet_model_path = \"EfficientNet-B3_checkpoints/EfficientNet-B3_epoch_20.pth\"\n",
    "efficientnet_checkpoint = torch.load(efficientnet_model_path, weights_only=False, map_location=device)\n",
    "efficientnet_model.load_state_dict(efficientnet_checkpoint['model_state_dict'])\n",
    "efficientnet_model.eval()\n",
    "calc_pAUC = pAUC(device, efficientnet_model, efficientnet_transform, X_test, y_test,  metadata_test)\n",
    "calc_pAUC.compute_pAUC()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac052bd",
   "metadata": {},
   "source": [
    "### pAUC calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4ecc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "efficientnet_model.eval()\n",
    "calc_pAUC = pAUC(device, efficientnet_trainer.model, efficientnet_trainernet_.transform, X_test, y_test,  metadata_test)\n",
    "calc_pAUC.compute_pAUC()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb181cd5",
   "metadata": {},
   "source": [
    "## ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5018a24-9c63-474d-9db9-eb72ac9b43e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "\n",
    "resnet_weights = ResNet50_Weights.DEFAULT\n",
    "resnet_transform = resnet_weights.transforms()\n",
    "\n",
    "resnet_train_dataset = HDF5Dataset(X_train, y_train, transform=resnet_transform)\n",
    "resnet_val_dataset = HDF5Dataset(X_val, y_val, transform=resnet_transform)\n",
    "resnet_model = resnet50(pretrained=True)\n",
    "resnet_model.fc = nn.Linear(resnet_model.fc.in_features, 1)\n",
    "\n",
    "lr = 4e-5\n",
    "num_epochs = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9559ce-cbd2-48c4-bc6d-5c4c10cdd23b",
   "metadata": {},
   "source": [
    "### Note: Still need to initialize Trainer!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd1f779",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_trainer = Trainer(device, resnet_train_dataset, resnet_val_dataset, \"ResNet50\", resnet_weights, resnet_transform, resnet_model, lr, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a5018e",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9779821f",
   "metadata": {},
   "source": [
    "### Load ResNet50 if already trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de725b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_model_path = \"ResNet50_checkpoints/ResNet50_epoch_20.pth\"\n",
    "resnet_checkpoint = torch.load(resnet_model_path, weights_only=False, map_location=device)\n",
    "resnet_model.load_state_dict(resnet_checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8cd26a",
   "metadata": {},
   "source": [
    "### pAUC Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013a4b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_model.eval()\n",
    "calc_pAUC = pAUC(device, resnet_model, resnet_transform, X_test, y_test,  metadata_test)\n",
    "calc_pAUC.compute_pAUC()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434e9a13",
   "metadata": {},
   "source": [
    "## Output predictions for train/val/test for all CNN models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca75e45a-208b-4927-89b3-aa0146aa1259",
   "metadata": {},
   "source": [
    "#### Convert CNNs's output predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768adf28-0940-439f-88ef-52c3d0f4ddc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "\n",
    "class TorchCNNWrapper(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, model, device='cpu', transform=None, threshold=0.5):\n",
    "        self.model = model.eval().to(device)\n",
    "        self.device = device\n",
    "        self.transform = transform\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def _prepare_image(self, img):\n",
    "        if isinstance(img, np.ndarray):\n",
    "            if img.dtype != np.uint8:\n",
    "                img = (img * 255).astype(np.uint8)\n",
    "            img = Image.fromarray(img)\n",
    "        return self.transform(img).unsqueeze(0).to(self.device)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        self.model.eval()\n",
    "        probs = []\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            for img in tqdm(X, desc=\"Predicting with CNN\"):\n",
    "                img_tensor = self._prepare_image(img)\n",
    "                logits = self.model(img_tensor)\n",
    "                prob = torch.sigmoid(logits).cpu().item()\n",
    "                probs.append(prob)\n",
    "                # probs.append([1 - prob, prob])\n",
    "    \n",
    "        return np.array(probs)\n",
    "\n",
    "    def predict(self, X):\n",
    "        probs = self.predict_proba(X)\n",
    "        \n",
    "        # return (probs[:, 1] >= self.threshold).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291ad03d-de31-4855-aa3c-196cc044e568",
   "metadata": {},
   "source": [
    "### Convert model into essemble model compatible format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b75513-3e13-4b50-b238-67ecccf2bac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "densenet_model.eval()\n",
    "densenet_wrapper = TorchCNNWrapper(\n",
    "    model=densenet_model,\n",
    "    device=device,\n",
    "    transform=densenet_transform\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629286f0-9079-4b65-adeb-06418eed2963",
   "metadata": {},
   "outputs": [],
   "source": [
    "densenet_wrapper_probas = densenet_wrapper.predict_proba(X_test[:20])[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40abe8f4-467a-4b8b-bd81-efeb743af1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "densenet_pd = pd.concat([\n",
    "    pd.Series(densenet_wrapper_probas, name=\"prediction\"),\n",
    "    pd.Series(y_test[:20], name=\"GroundTruth\"),\n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5fc7962-4126-4d68-8d2d-14594653627d",
   "metadata": {},
   "outputs": [],
   "source": [
    "densenet_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99a82e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_predictions(model, dataset):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for img in tqdm(dataset, desc=\"Predicting with CNN\"):\n",
    "            img_tensor = img.unsqueeze(0).to(device)\n",
    "            logits = model(img_tensor)\n",
    "            prob = torch.sigmoid(logits).cpu().item()\n",
    "            predictions.append(prob)\n",
    "    return np.array(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb9eb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "densenet_model.eval()\n",
    "efficientnet_model.eval()\n",
    "resnet_model.eval()\n",
    "\n",
    "# generate predictions for training set\n",
    "densenet_train_preds = get_model_predictions(densenet_model, densenet_train_dataset)\n",
    "efficientnet_train_preds = get_model_predictions(efficientnet_model, efficientnet_train_dataset)\n",
    "resnet_train_preds = get_model_predictions(resnet_model, resnet_train_dataset)\n",
    "\n",
    "# use pd concat to combine the predictions\n",
    "train_preds = pd.concat([\n",
    "    pd.Series(metadata_train['isic_id'], name=\"isic_id\"),\n",
    "    pd.Series(densenet_train_preds, name=\"densenet\"),\n",
    "    pd.Series(efficientnet_train_preds, name=\"efficientnet\"),\n",
    "    pd.Series(resnet_train_preds, name=\"resnet\"),\n",
    "    pd.Series(y_train, name=\"GroundTruth\")\n",
    "], axis=1)\n",
    "\n",
    "# generate predictions for validation set\n",
    "densenet_val_preds = get_model_predictions(densenet_model, densenet_val_dataset)\n",
    "efficientnet_val_preds = get_model_predictions(efficientnet_model, efficientnet_val_dataset)\n",
    "resnet_val_preds = get_model_predictions(resnet_model, resnet_val_dataset)\n",
    "\n",
    "# use pd concat to combine the predictions\n",
    "val_preds = pd.concat([\n",
    "    pd.Series(metadata_val['isic_id'], name=\"isic_id\"),\n",
    "    pd.Series(densenet_val_preds, name=\"densenet\"),\n",
    "    pd.Series(efficientnet_val_preds, name=\"efficientnet\"),\n",
    "    pd.Series(resnet_val_preds, name=\"resnet\"),\n",
    "    pd.Series(y_val, name=\"GroundTruth\")\n",
    "], axis=1)\n",
    "\n",
    "# generate predictions for test set\n",
    "densenet_test_preds = get_model_predictions(densenet_model, densenet_val_dataset)\n",
    "efficientnet_test_preds = get_model_predictions(efficientnet_model, efficientnet_val_dataset)\n",
    "resnet_test_preds = get_model_predictions(resnet_model, resnet_val_dataset)\n",
    "\n",
    "# use pd concat to combine the predictions\n",
    "test_preds = pd.concat([\n",
    "    pd.Series(metadata_test['isic_id'], name=\"isic_id\"),\n",
    "    pd.Series(densenet_test_preds, name=\"densenet\"),\n",
    "    pd.Series(efficientnet_test_preds, name=\"efficientnet\"),\n",
    "    pd.Series(resnet_test_preds, name=\"resnet\"),\n",
    "    pd.Series(y_test, name=\"GroundTruth\")\n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343a4689",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the predictions to csv\n",
    "train_preds.to_csv(\"train_predictions.csv\", index=False)\n",
    "val_preds.to_csv(\"val_predictions.csv\", index=False)\n",
    "test_preds.to_csv(\"test_predictions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489439a3",
   "metadata": {},
   "source": [
    "## Load Tree based models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1870b68",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6f1315-44d5-45a4-b420-989fbd8e911a",
   "metadata": {},
   "source": [
    "### Light GBM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4407d2-c9ad-470a-bbbf-ee5db2469f8c",
   "metadata": {},
   "source": [
    "### CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722172e9-d534-4767-9311-6796213b4360",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
