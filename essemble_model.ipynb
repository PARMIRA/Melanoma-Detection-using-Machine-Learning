{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c96576d",
   "metadata": {},
   "source": [
    "# Assemble Model using DenseNet, EfficientNet, ResNet50, XGBoost, Light GBM, and CatBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0552969-dff4-4a3e-9bb9-361925f9e4c4",
   "metadata": {},
   "source": [
    "## Here's datasets you will need to run\n",
    "- train-image.hdf5\n",
    "- train-metadata.csv\n",
    "- augmented_data.hdf5\n",
    "- augmented_metadata.csv\n",
    "- isic_image.hdf5\n",
    "- isic_metadata.csv\n",
    "- test-image.hdf5\n",
    "- test-metadata.csv\n",
    "## Here's the models/paths you need to run without training the CNN model\n",
    "- DenseNet121_checkpoints/DenseNet121_epoch_20.pth\n",
    "- EfficientNet-B3_checkpoints/EfficientNet-B3_epoch_20.pth\n",
    "- ResNet50_checkpoints/ResNet50_epoch_20.pth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb04e90",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65dd2089",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import torch\n",
    "import cv2\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms, models\n",
    "from torchvision.models import densenet121, DenseNet121_Weights\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from tqdm import tqdm\n",
    "# from dataset import HDF5Dataset\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from isic_metric import score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4863765d",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a0a64a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "labels = []\n",
    "metadata = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a898a1d",
   "metadata": {},
   "source": [
    "### First, load the malignant data from original database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa7f05a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_train_hdf5_path = 'train-image.hdf5'\n",
    "original_train_metadata_path = 'train-metadata.csv'\n",
    "original_train_metadata = pd.read_csv(original_train_metadata_path,low_memory=False)   \n",
    "original_train_hdf5 = h5py.File(original_train_hdf5_path, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31be5557",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▊    | 235106/401059 [00:10<00:07, 21380.02it/s]"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(original_train_metadata))):\n",
    "    if original_train_metadata.iloc[i]['target'] == 0: # skip non-malignant images\n",
    "        continue\n",
    "    image_id = original_train_metadata.iloc[i]['isic_id']\n",
    "    image = original_train_hdf5[image_id][()]\n",
    "    image = np.frombuffer(image, dtype=np.uint8)\n",
    "    image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
    "    image = cv2.resize(image, (128, 128))\n",
    "    image = image / 255\n",
    "    \n",
    "    images.append(image)\n",
    "    labels.append(1)\n",
    "    metadata.append(original_train_metadata.iloc[i])\n",
    "    \n",
    "# original_train_hdf5.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3c9664",
   "metadata": {},
   "source": [
    "### Second, load the augmented malignant images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e157a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_malignant_hdf5_path = 'augmented_data.hdf5'\n",
    "augmented_malignant_metadata_path = 'augmented_metadata.csv'\n",
    "augmented_malignant_metadata = pd.read_csv(augmented_malignant_metadata_path,low_memory=False)\n",
    "augmented_malignant_hdf5 = h5py.File(augmented_malignant_hdf5_path, 'r')\n",
    "n_augmentations = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d51fd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(len(augmented_malignant_metadata))):\n",
    "\n",
    "    for j in range(n_augmentations):\n",
    "        image_id = f\"{augmented_malignant_metadata.iloc[i]['isic_id']}_aug{j}\"\n",
    "        image = augmented_malignant_hdf5[image_id][()]\n",
    "        image = np.frombuffer(image, dtype=np.uint8)\n",
    "        image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
    "        # show image\n",
    "        # plt.imshow(image)\n",
    "        # plt.axis('off')\n",
    "        # plt.show()\n",
    "        image = cv2.resize(image, (128, 128))\n",
    "        image = image / 255\n",
    "    \n",
    "        images.append(image)\n",
    "        labels.append(1)\n",
    "        metadata.append(augmented_malignant_metadata.iloc[i])\n",
    "    \n",
    "augmented_malignant_hdf5.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5be58e",
   "metadata": {},
   "source": [
    "### Third, load the ISIC full database's malignant examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a82feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "isic_metadata_path = 'isic_metadata.csv'\n",
    "isic_hdf5_path = 'isic_image.hdf5'\n",
    "isic_metadata = pd.read_csv(isic_metadata_path,low_memory=False)\n",
    "isic_hdf5 = h5py.File(isic_hdf5_path, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0569ae99",
   "metadata": {},
   "outputs": [],
   "source": [
    "malignant_count = 0\n",
    "for i in tqdm(range(len(isic_metadata))):\n",
    "    if isic_metadata.iloc[i]['benign_malignant'] == 'malignant': # skip non-malignant images\n",
    "        image_id = isic_metadata.iloc[i]['isic_id']\n",
    "        image = isic_hdf5[image_id][()]\n",
    "        image = np.frombuffer(image, dtype=np.uint8)\n",
    "        image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
    "        image = cv2.resize(image, (128, 128))\n",
    "        image = image / 255\n",
    "        malignant_count += 1\n",
    "        \n",
    "        images.append(image)\n",
    "        labels.append(1)\n",
    "        metadata.append(isic_metadata.iloc[i])\n",
    "print(f\"malignant count: {malignant_count}\")\n",
    "isic_hdf5.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef13ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "malignant_count = len(labels)\n",
    "print(f\"malignant count: {malignant_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b978ee",
   "metadata": {},
   "source": [
    "### Lastly, load the same amount of beign data from original database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199f2b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "benign_loaded = 0\n",
    "\n",
    "pbar = tqdm(total=malignant_count, desc=\"Loading benign images\")\n",
    "while benign_loaded < malignant_count:\n",
    "    if original_train_metadata.iloc[idx]['target'] == 0:\n",
    "        image_id = original_train_metadata.iloc[idx]['isic_id']\n",
    "        image = original_train_hdf5[image_id][()]\n",
    "        image = np.frombuffer(image, dtype=np.uint8)\n",
    "        image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
    "        image = cv2.resize(image, (128, 128))\n",
    "        image = image / 255\n",
    "        images.append(image)\n",
    "        labels.append(0)\n",
    "        metadata.append(original_train_metadata.iloc[idx])\n",
    "        benign_loaded += 1\n",
    "        pbar.update(1)\n",
    "    idx += 1\n",
    "pbar.close()\n",
    "\n",
    "original_train_hdf5.close()\n",
    "print(f\"benign count: {benign_loaded}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76c222a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(images))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188a93fb",
   "metadata": {},
   "source": [
    "### Generate Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a373bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import HDF5Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 70% for training\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    images, labels, test_size=0.3, stratify=labels, random_state=42\n",
    ")\n",
    "\n",
    "# 15% validation, 15% testing\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42\n",
    ")\n",
    "\n",
    "# split metadata\n",
    "metadata_train, metadata_temp = train_test_split(\n",
    "    metadata, test_size=0.3, stratify=labels, random_state=42\n",
    ")\n",
    "metadata_val, metadata_test = train_test_split(\n",
    "    metadata_temp, test_size=0.5, stratify=y_temp, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385d384e-0605-4008-a2c6-988c0c2ec895",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Training data: {len(X_train)}')\n",
    "print(f'Validation data: {len(X_val)}')\n",
    "print(f'Test data: {len(X_test)}')\n",
    "print(f'Metadata Training data: {len(metadata_train)}')\n",
    "print(f'Metadata Validation data: {len(metadata_val)}')\n",
    "print(f'Metadata Test data: {len(metadata_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b29e88-926c-4dbd-bfae-0a3daef94e49",
   "metadata": {},
   "source": [
    "### Export isic id for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9015f04-6357-4f3f-a929-798dae19e288",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e4938933",
   "metadata": {},
   "source": [
    "### Load ISIC Competition Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3dc199a",
   "metadata": {},
   "outputs": [],
   "source": [
    "isic_test_metadata_path = 'test-metadata.csv'\n",
    "isic_test_metadata = pd.read_csv(isic_test_metadata_path,low_memory=False)\n",
    "isic_test_hdf5_path = 'test-image.hdf5'\n",
    "isic_test_hdf5 = h5py.File(isic_test_hdf5_path, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65ba078",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "X_test_isic = []\n",
    "X_test_isic_id = []\n",
    "metadata_test_isic = []\n",
    "for i in tqdm(range(len(isic_test_metadata))):\n",
    "    image_id = isic_test_metadata.iloc[i]['isic_id']\n",
    "    image = isic_test_hdf5[image_id][()]\n",
    "    image = np.frombuffer(image, dtype=np.uint8)\n",
    "    image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
    "    image = cv2.resize(image, (128, 128))\n",
    "    image = image / 255\n",
    "    \n",
    "    # since it does not have labels, we need to manualy ensure it works with the models\n",
    "    if isinstance(image, np.ndarray):\n",
    "        # First ensure it's uint8\n",
    "        if image.dtype != np.uint8:\n",
    "            image = (image * 255).astype(np.uint8)\n",
    "        image = Image.fromarray(image)\n",
    "    X_test_isic.append(image)\n",
    "    metadata_test_isic.append(isic_test_metadata.iloc[i])\n",
    "    X_test_isic_id.append(image_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc78d322",
   "metadata": {},
   "source": [
    "## Load CNN models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c34365c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b756755",
   "metadata": {},
   "source": [
    "### DenseNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dcc2dff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import densenet121, DenseNet121_Weights\n",
    "from ModelTrainer import Trainer\n",
    "densenet_weights = DenseNet121_Weights.DEFAULT\n",
    "densenet_transform = densenet_weights.transforms()\n",
    "densenet_train_dataset = HDF5Dataset(X_train, y_train, augment=True, transform=densenet_transform)\n",
    "densenet_val_dataset = HDF5Dataset(X_val, y_val, augment=False, transform=densenet_transform)\n",
    "densenet_model = densenet121(weights=densenet_weights)\n",
    "lr = 1e-4\n",
    "num_epochs = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c5f922-ec03-40cd-9e78-b4503c025aa4",
   "metadata": {},
   "source": [
    "#### NOTE!! Still need to run this block below if loading weights!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "93bfeb98-614b-4fca-964c-42f354131128",
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_net_trainer = Trainer(device, densenet_train_dataset, densenet_val_dataset, \"DenseNet121\", densenet_weights, densenet_transform, densenet_model, lr, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c247174f-cfff-4084-b71f-f95c879a1818",
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_net_trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca75e45a-208b-4927-89b3-aa0146aa1259",
   "metadata": {},
   "source": [
    "#### Convert CNNs's output predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "768adf28-0940-439f-88ef-52c3d0f4ddc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "\n",
    "class TorchCNNWrapper(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, model, device='cpu', transform=None, threshold=0.5):\n",
    "        self.model = model.eval().to(device)\n",
    "        self.device = device\n",
    "        self.transform = transform\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def _prepare_image(self, img):\n",
    "        if isinstance(img, np.ndarray):\n",
    "            if img.dtype != np.uint8:\n",
    "                img = (img * 255).astype(np.uint8)\n",
    "            img = Image.fromarray(img)\n",
    "        return self.transform(img).unsqueeze(0).to(self.device)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        self.model.eval()\n",
    "        probs = []\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            for img in tqdm(X, desc=\"Predicting with CNN\"):\n",
    "                img_tensor = self._prepare_image(img)\n",
    "                logits = self.model(img_tensor)\n",
    "                prob = torch.sigmoid(logits).cpu().item()\n",
    "                probs.append([1 - prob, prob])\n",
    "    \n",
    "        return np.array(probs)\n",
    "\n",
    "    def predict(self, X):\n",
    "        probs = self.predict_proba(X)\n",
    "        return (probs[:, 1] >= self.threshold).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea77a71",
   "metadata": {},
   "source": [
    "### Load model if already trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dad0556c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "densenet_model_path = \"DenseNet121_checkpoints/DenseNet121_epoch_20.pth\"\n",
    "densenet_checkpoint = torch.load(densenet_model_path, weights_only=False, map_location=device)\n",
    "densenet_model.load_state_dict(densenet_checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291ad03d-de31-4855-aa3c-196cc044e568",
   "metadata": {},
   "source": [
    "### Convert model into essemble model compatible format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "16b75513-3e13-4b50-b238-67ecccf2bac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "densenet_model.eval()\n",
    "densenet_wrapper = TorchCNNWrapper(\n",
    "    model=densenet_model,\n",
    "    device=device,\n",
    "    transform=densenet_transform\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "629286f0-9079-4b65-adeb-06418eed2963",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting with CNN: 100%|██████████| 20/20 [00:00<00:00, 77.18it/s]\n"
     ]
    }
   ],
   "source": [
    "densenet_wrapper_probas = densenet_wrapper.predict_proba(X_test[:20])[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "40abe8f4-467a-4b8b-bd81-efeb743af1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "densenet_pd = pd.concat([\n",
    "    pd.Series(densenet_wrapper_probas, name=\"prediction\"),\n",
    "    pd.Series(y_test[:20], name=\"GroundTruth\"),\n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e5fc7962-4126-4d68-8d2d-14594653627d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "      <th>GroundTruth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.407504e-04</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.814827e-07</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.999537e-01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.194129e-05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.149878e-08</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     prediction  GroundTruth\n",
       "0  1.407504e-04            0\n",
       "1  5.814827e-07            0\n",
       "2  9.999537e-01            1\n",
       "3  2.194129e-05            0\n",
       "4  2.149878e-08            0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "densenet_pd.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630f6b59",
   "metadata": {},
   "source": [
    "### Calculate test pAUC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cace52ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5838/5838 [01:14<00:00, 78.79it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.19820985965595456"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from calc_pauc import pAUC\n",
    "calc_pAUC = pAUC(device, densenet_model, densenet_transform, X_test, y_test,  metadata_test)\n",
    "calc_pAUC.compute_pAUC()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe25088-416d-456f-b84d-77a9ca36d32c",
   "metadata": {},
   "source": [
    "## EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4914910f-00ef-48d5-b255-de089719c2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import efficientnet_b3, EfficientNet_B3_Weights\n",
    "efficientnet_weights = EfficientNet_B3_Weights.DEFAULT\n",
    "efficientnet_transform = efficientnet_weights.transforms()\n",
    "efficientnet_train_dataset = HDF5Dataset(X_train, y_train, augment=True, transform=efficientnet_transform)\n",
    "efficientnet_val_dataset = HDF5Dataset(X_val, y_val, augment=False, transform=efficientnet_transform)\n",
    "efficientnet_model = efficientnet_b3(weights=efficientnet_weights)\n",
    "lr = 3e-5\n",
    "num_epochs = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a52a6f-9457-4d1e-8624-d3f59911dff2",
   "metadata": {},
   "source": [
    "### Note: Still need to initialize Trainer!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a0bc69c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EfficientNet Configuration\n"
     ]
    }
   ],
   "source": [
    "efficientnet_trainer = Trainer(device, efficientnet_train_dataset, efficientnet_val_dataset, \"EfficientNet-B3\", efficientnet_weights, efficientnet_transform, efficientnet_model, lr, num_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201a9cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "efficientnet_trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca1ab4b",
   "metadata": {},
   "source": [
    "### Load EfficientNet Model if already trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ad971031",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "efficientnet_model_path = \"EfficientNet-B3_checkpoints/EfficientNet-B3_epoch_20.pth\"\n",
    "efficientnet_checkpoint = torch.load(efficientnet_model_path, weights_only=False, map_location=device)\n",
    "efficientnet_model.load_state_dict(efficientnet_checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac052bd",
   "metadata": {},
   "source": [
    "### pAUC calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6f4ecc2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5838/5838 [01:03<00:00, 91.47it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.19805576182131668"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "efficientnet_model.eval()\n",
    "calc_pAUC = pAUC(device, efficientnet_model, efficientnet_transform, X_test, y_test,  metadata_test)\n",
    "calc_pAUC.compute_pAUC()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb181cd5",
   "metadata": {},
   "source": [
    "## ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f5018a24-9c63-474d-9db9-eb72ac9b43e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mperform/.local/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/mperform/.local/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "\n",
    "resnet_weights = ResNet50_Weights.DEFAULT\n",
    "resnet_transform = resnet_weights.transforms()\n",
    "\n",
    "resnet_train_dataset = HDF5Dataset(X_train, y_train, transform=resnet_transform)\n",
    "resnet_val_dataset = HDF5Dataset(X_val, y_val, transform=resnet_transform)\n",
    "resnet_model = resnet50(pretrained=True)\n",
    "resnet_model.fc = nn.Linear(resnet_model.fc.in_features, 1)\n",
    "\n",
    "lr = 4e-5\n",
    "num_epochs = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9559ce-cbd2-48c4-bc6d-5c4c10cdd23b",
   "metadata": {},
   "source": [
    "### Note: Still need to initialize Trainer!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9fd1f779",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_trainer = Trainer(device, resnet_train_dataset, resnet_val_dataset, \"ResNet50\", resnet_weights, resnet_transform, resnet_model, lr, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a5018e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20: 100%|██████████| 213/213 [01:11<00:00,  2.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Acc = 0.9808, Precision = 0.9986, Recall = 0.9630, F1 = 0.9805, pAUC = 0.1986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/20: 100%|██████████| 213/213 [01:12<00:00,  2.92it/s]\n"
     ]
    }
   ],
   "source": [
    "resnet_trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9779821f",
   "metadata": {},
   "source": [
    "### Load ResNet50 if already trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "de725b47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet_model_path = \"ResNet50_checkpoints/ResNet50_epoch_20.pth\"\n",
    "resnet_checkpoint = torch.load(resnet_model_path, weights_only=False, map_location=device)\n",
    "resnet_model.load_state_dict(resnet_checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8cd26a",
   "metadata": {},
   "source": [
    "### pAUC Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "013a4b59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5838/5838 [00:31<00:00, 185.97it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.19694362847704505"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet_model.eval()\n",
    "calc_pAUC = pAUC(device, resnet_model, resnet_transform, X_test, y_test,  metadata_test)\n",
    "calc_pAUC.compute_pAUC()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489439a3",
   "metadata": {},
   "source": [
    "## Load Tree based models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1870b68",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6f1315-44d5-45a4-b420-989fbd8e911a",
   "metadata": {},
   "source": [
    "### Light GBM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4407d2-c9ad-470a-bbbf-ee5db2469f8c",
   "metadata": {},
   "source": [
    "### CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722172e9-d534-4767-9311-6796213b4360",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
