{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afc526f2",
   "metadata": {},
   "source": [
    "# This trains a ResNet50 for classification on the skin cancer images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4ae8f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import torch\n",
    "import cv2\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms, models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from tqdm import tqdm\n",
    "from ResNet_baseline import HDF5Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f864bce4",
   "metadata": {},
   "source": [
    "## Load data and preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8e80d7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4w/dhmdb97x63lfq799n_46pwc80000gn/T/ipykernel_70500/1558046119.py:2: DtypeWarning: Columns (51,52) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  metadata = pd.read_csv(\"train-metadata.csv\")\n"
     ]
    }
   ],
   "source": [
    "# Load metadata\n",
    "metadata = pd.read_csv(\"train-metadata.csv\")\n",
    "hdf5 = h5py.File(\"train-image.hdf5\", \"r\")\n",
    "\n",
    "# Sample balanced malignant and benign\n",
    "malignant_ids = metadata[metadata[\"target\"] == 1].sample(n=393, random_state=42)[\"isic_id\"].tolist()\n",
    "benign_ids = metadata[metadata[\"target\"] == 0].sample(n=393, random_state=42)[\"isic_id\"].tolist()\n",
    "\n",
    "def load_images(ids):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for image_id in ids:\n",
    "        image = hdf5[image_id][()]\n",
    "        image = np.frombuffer(image, dtype=np.uint8)\n",
    "        image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
    "        image = cv2.resize(image, (128, 128))\n",
    "        images.append(image)\n",
    "        labels.append(1 if image_id in malignant_ids else 0)\n",
    "    return images, labels\n",
    "\n",
    "images_mal, labels_mal = load_images(malignant_ids)\n",
    "images_ben, labels_ben = load_images(benign_ids)\n",
    "\n",
    "# Combine and split\n",
    "all_images = np.array(images_mal + images_ben)\n",
    "all_labels = np.array(labels_mal + labels_ben)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(all_images, all_labels, test_size=0.1, stratify=all_labels, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5422147e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = HDF5Dataset(X_train, y_train, augment=True)\n",
    "val_dataset = HDF5Dataset(X_val, y_val, augment=False)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=1)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac3a6d3",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f48e36ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5051cb14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(\"checkpoints\", exist_ok=True)\n",
    "model = models.resnet50(pretrained=True)\n",
    "model.fc = nn.Linear(model.fc.in_features, 1)  # binary classification (logit)\n",
    "model = model.to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0fb231f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 20\n",
    "train_losses, val_losses = [], []\n",
    "val_accuracies = []\n",
    "val_precisions = []\n",
    "val_recalls = []\n",
    "val_f1s = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de854d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for inputs, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.float().unsqueeze(1).to(device)  # [B, 1]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    train_losses.append(epoch_loss / len(train_loader))\n",
    "\n",
    "    # === Validation ===\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    preds, targets = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.float().unsqueeze(1).to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            preds.extend(torch.sigmoid(outputs).cpu().numpy())\n",
    "            targets.extend(labels.cpu().numpy())\n",
    "\n",
    "    val_losses.append(val_loss / len(val_loader))\n",
    "    val_auc = roc_auc_score(targets, preds)\n",
    "    \n",
    "    # Threshold predictions at 0.5\n",
    "    pred_labels = (np.array(preds) >= 0.5).astype(int)\n",
    "    true_labels = np.array(targets).astype(int)\n",
    "\n",
    "    val_acc = accuracy_score(true_labels, pred_labels)\n",
    "    val_precision = precision_score(true_labels, pred_labels)\n",
    "    val_recall = recall_score(true_labels, pred_labels)\n",
    "    val_f1 = f1_score(true_labels, pred_labels)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}: Acc = {val_acc:.4f}, Precision = {val_precision:.4f}, Recall = {val_recall:.4f}, F1 = {val_f1:.4f}\") \n",
    "    val_accuracies.append(val_acc)\n",
    "    val_precisions.append(val_precision)\n",
    "    val_recalls.append(val_recall)\n",
    "    val_f1s.append(val_f1)\n",
    "    torch.save({\n",
    "        'epoch': epoch + 1,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'train_loss': train_losses[-1],\n",
    "        'val_loss': val_losses[-1],\n",
    "        'val_auc': val_auc\n",
    "    }, f\"checkpoints/resnet50_epoch_{epoch+1}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2712095",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_losses, label='Train')\n",
    "plt.plot(val_losses, label='Validation')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"ResNet50 Training Loss\")\n",
    "plt.legend()\n",
    "plt.savefig(\"resnet50_loss_curve.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c276b14b",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f3db4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet50(pretrained=False)\n",
    "model.fc = nn.Linear(model.fc.in_features, 1)\n",
    "model.load_state_dict(torch.load(\"resnet50_epoch_20.pth\"))\n",
    "model.eval()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c956937",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metadata = pd.read_csv(\"test-metadata.csv\")\n",
    "test_hdf5 = h5py.File(\"test-image.hdf5\", \"r\")\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5]*3, [0.5]*3)\n",
    "])\n",
    "\n",
    "# Store predictions\n",
    "results = []\n",
    "\n",
    "for i in tqdm(range(len(test_metadata))):\n",
    "    image_id = test_metadata.iloc[i][\"isic_id\"]\n",
    "    image_data = test_hdf5[image_id][()]\n",
    "    image = np.frombuffer(image_data, dtype=np.uint8)\n",
    "    image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
    "    image = cv2.resize(image, (128, 128))\n",
    "    image = transform(image).unsqueeze(0).to(device)  # [1, 3, 128, 128]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(image)\n",
    "        prob = torch.sigmoid(output).item()\n",
    "\n",
    "    results.append((image_id, prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf2e5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results, columns=[\"isic_id\", \"predicted_probability\"])\n",
    "results_df[\"predicted_label\"] = (results_df[\"predicted_probability\"] >= 0.5).astype(int)\n",
    "results_df.to_csv(\"test_predictions.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
