{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c96576d",
   "metadata": {},
   "source": [
    "# Assemble Model using DenseNet, EfficientNet, ResNet50, XGBoost, Light GBM, and CatBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb04e90",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65dd2089",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import torch\n",
    "import cv2\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms, models\n",
    "from torchvision.models import densenet121, DenseNet121_Weights\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from tqdm import tqdm\n",
    "# from dataset import HDF5Dataset\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from isic_metric import score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4863765d",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0a64a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a898a1d",
   "metadata": {},
   "source": [
    "### First, load the malignant data from original database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7f05a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_train_hdf5_path = 'train-image.hdf5'\n",
    "original_train_metadata_path = 'train-metadata.csv'\n",
    "original_train_metadata = pd.read_csv(original_train_metadata_path,low_memory=False)   \n",
    "original_train_hdf5 = h5py.File(original_train_hdf5_path, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31be5557",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(len(original_train_metadata))):\n",
    "    if original_train_metadata.iloc[i]['target'] == 0: # skip non-malignant images\n",
    "        continue\n",
    "    image_id = original_train_metadata.iloc[i]['isic_id']\n",
    "    image = original_train_hdf5[image_id][()]\n",
    "    image = np.frombuffer(image, dtype=np.uint8)\n",
    "    image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
    "    image = cv2.resize(image, (128, 128))\n",
    "    image = image / 255\n",
    "    \n",
    "    images.append(image)\n",
    "    labels.append(1)\n",
    "    \n",
    "# original_train_hdf5.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3c9664",
   "metadata": {},
   "source": [
    "### Second, load the augmented malignant images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e157a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_malignant_hdf5_path = 'augmented_data.hdf5'\n",
    "augmented_malignant_metadata_path = 'augmented_metadata.csv'\n",
    "augmented_malignant_metadata = pd.read_csv(augmented_malignant_metadata_path,low_memory=False)\n",
    "augmented_malignant_hdf5 = h5py.File(augmented_malignant_hdf5_path, 'r')\n",
    "n_augmentations = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d51fd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(len(augmented_malignant_metadata))):\n",
    "\n",
    "    for j in range(n_augmentations):\n",
    "        image_id = f\"{augmented_malignant_metadata.iloc[i]['isic_id']}_aug{j}\"\n",
    "        image = augmented_malignant_hdf5[image_id][()]\n",
    "        image = np.frombuffer(image, dtype=np.uint8)\n",
    "        image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
    "        # show image\n",
    "        # plt.imshow(image)\n",
    "        # plt.axis('off')\n",
    "        # plt.show()\n",
    "        image = cv2.resize(image, (128, 128))\n",
    "        image = image / 255\n",
    "    \n",
    "        images.append(image)\n",
    "        labels.append(1)\n",
    "    \n",
    "augmented_malignant_hdf5.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5be58e",
   "metadata": {},
   "source": [
    "### Third, load the ISIC full database's malignant examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a82feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "isic_metadata_path = 'isic_metadata.csv'\n",
    "isic_hdf5_path = 'isic_image.hdf5'\n",
    "isic_metadata = pd.read_csv(isic_metadata_path,low_memory=False)\n",
    "isic_hdf5 = h5py.File(isic_hdf5_path, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0569ae99",
   "metadata": {},
   "outputs": [],
   "source": [
    "malignant_count = 0\n",
    "for i in tqdm(range(len(isic_metadata))):\n",
    "    if isic_metadata.iloc[i]['benign_malignant'] == 'malignant': # skip non-malignant images\n",
    "        image_id = isic_metadata.iloc[i]['isic_id']\n",
    "        image = isic_hdf5[image_id][()]\n",
    "        image = np.frombuffer(image, dtype=np.uint8)\n",
    "        image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
    "        image = cv2.resize(image, (128, 128))\n",
    "        image = image / 255\n",
    "        malignant_count += 1\n",
    "        \n",
    "        images.append(image)\n",
    "        labels.append(1)\n",
    "print(f\"malignant count: {malignant_count}\")\n",
    "isic_hdf5.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef13ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "malignant_count = len(labels)\n",
    "print(f\"malignant count: {malignant_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b978ee",
   "metadata": {},
   "source": [
    "### Lastly, load the same amount of beign data from original database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199f2b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "benign_loaded = 0\n",
    "\n",
    "pbar = tqdm(total=malignant_count, desc=\"Loading benign images\")\n",
    "while benign_loaded < malignant_count:\n",
    "    if original_train_metadata.iloc[idx]['target'] == 0:\n",
    "        image_id = original_train_metadata.iloc[idx]['isic_id']\n",
    "        image = original_train_hdf5[image_id][()]\n",
    "        image = np.frombuffer(image, dtype=np.uint8)\n",
    "        image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
    "        image = cv2.resize(image, (128, 128))\n",
    "        image = image / 255\n",
    "        images.append(image)\n",
    "        labels.append(0)\n",
    "        benign_loaded += 1\n",
    "        pbar.update(1)\n",
    "    idx += 1\n",
    "pbar.close()\n",
    "\n",
    "original_train_hdf5.close()\n",
    "print(f\"benign count: {benign_loaded}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76c222a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(images))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188a93fb",
   "metadata": {},
   "source": [
    "### Generate Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a373bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import HDF5Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(images, labels, test_size=0.2, stratify=labels, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc78d322",
   "metadata": {},
   "source": [
    "## Load CNN models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c34365c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b756755",
   "metadata": {},
   "source": [
    "### DenseNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc2dff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import densenet121, DenseNet121_Weights\n",
    "from ModelTrainer import Trainer\n",
    "densenet_weights = DenseNet121_Weights.DEFAULT\n",
    "densenet_transform = densenet_weights.transforms()\n",
    "densenet_train_dataset = HDF5Dataset(X_train, y_train, augment=True, transform=densenet_transform)\n",
    "densenet_val_dataset = HDF5Dataset(X_val, y_val, augment=False, transform=densenet_transform)\n",
    "densenet_model = densenet121(weights=densenet_weights)\n",
    "lr = 1e-5\n",
    "num_epochs = 20\n",
    "dense_net_trainer = Trainer(device, densenet_train_dataset, densenet_val_dataset, \"DenseNet121\", densenet_weights, densenet_transform, densenet_model, lr, num_epochs)\n",
    "dense_net_trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
