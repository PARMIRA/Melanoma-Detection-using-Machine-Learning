{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c96576d",
   "metadata": {},
   "source": [
    "# Assemble Model using DenseNet, EfficientNet, ResNet50, XGBoost, Light GBM, and CatBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb04e90",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65dd2089",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import torch\n",
    "import cv2\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms, models\n",
    "from torchvision.models import densenet121, DenseNet121_Weights\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from tqdm import tqdm\n",
    "# from dataset import HDF5Dataset\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from isic_metric import score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4863765d",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a0a64a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "labels = []\n",
    "metadata = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a898a1d",
   "metadata": {},
   "source": [
    "### First, load the malignant data from original database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa7f05a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_train_hdf5_path = 'train-image.hdf5'\n",
    "original_train_metadata_path = 'train-metadata.csv'\n",
    "original_train_metadata = pd.read_csv(original_train_metadata_path,low_memory=False)   \n",
    "original_train_hdf5 = h5py.File(original_train_hdf5_path, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31be5557",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 401059/401059 [00:19<00:00, 20853.92it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(original_train_metadata))):\n",
    "    if original_train_metadata.iloc[i]['target'] == 0: # skip non-malignant images\n",
    "        continue\n",
    "    image_id = original_train_metadata.iloc[i]['isic_id']\n",
    "    image = original_train_hdf5[image_id][()]\n",
    "    image = np.frombuffer(image, dtype=np.uint8)\n",
    "    image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
    "    image = cv2.resize(image, (128, 128))\n",
    "    image = image / 255\n",
    "    \n",
    "    images.append(image)\n",
    "    labels.append(1)\n",
    "    metadata.append(original_train_metadata.iloc[i])\n",
    "    \n",
    "# original_train_hdf5.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3c9664",
   "metadata": {},
   "source": [
    "### Second, load the augmented malignant images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45e157a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_malignant_hdf5_path = 'augmented_data.hdf5'\n",
    "augmented_malignant_metadata_path = 'augmented_metadata.csv'\n",
    "augmented_malignant_metadata = pd.read_csv(augmented_malignant_metadata_path,low_memory=False)\n",
    "augmented_malignant_hdf5 = h5py.File(augmented_malignant_hdf5_path, 'r')\n",
    "n_augmentations = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d51fd96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1965/1965 [00:08<00:00, 229.63it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(augmented_malignant_metadata))):\n",
    "\n",
    "    for j in range(n_augmentations):\n",
    "        image_id = f\"{augmented_malignant_metadata.iloc[i]['isic_id']}_aug{j}\"\n",
    "        image = augmented_malignant_hdf5[image_id][()]\n",
    "        image = np.frombuffer(image, dtype=np.uint8)\n",
    "        image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
    "        # show image\n",
    "        # plt.imshow(image)\n",
    "        # plt.axis('off')\n",
    "        # plt.show()\n",
    "        image = cv2.resize(image, (128, 128))\n",
    "        image = image / 255\n",
    "    \n",
    "        images.append(image)\n",
    "        labels.append(1)\n",
    "        metadata.append(augmented_malignant_metadata.iloc[i])\n",
    "    \n",
    "augmented_malignant_hdf5.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5be58e",
   "metadata": {},
   "source": [
    "### Third, load the ISIC full database's malignant examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77a82feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "isic_metadata_path = 'isic_metadata.csv'\n",
    "isic_hdf5_path = 'isic_image.hdf5'\n",
    "isic_metadata = pd.read_csv(isic_metadata_path,low_memory=False)\n",
    "isic_hdf5 = h5py.File(isic_hdf5_path, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0569ae99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 81722/81722 [00:25<00:00, 3186.92it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "malignant count: 9239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "malignant_count = 0\n",
    "for i in tqdm(range(len(isic_metadata))):\n",
    "    if isic_metadata.iloc[i]['benign_malignant'] == 'malignant': # skip non-malignant images\n",
    "        image_id = isic_metadata.iloc[i]['isic_id']\n",
    "        image = isic_hdf5[image_id][()]\n",
    "        image = np.frombuffer(image, dtype=np.uint8)\n",
    "        image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
    "        image = cv2.resize(image, (128, 128))\n",
    "        image = image / 255\n",
    "        malignant_count += 1\n",
    "        \n",
    "        images.append(image)\n",
    "        labels.append(1)\n",
    "        metadata.append(isic_metadata.iloc[i])\n",
    "print(f\"malignant count: {malignant_count}\")\n",
    "isic_hdf5.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eef13ace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "malignant count: 19457\n"
     ]
    }
   ],
   "source": [
    "malignant_count = len(labels)\n",
    "print(f\"malignant count: {malignant_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b978ee",
   "metadata": {},
   "source": [
    "### Lastly, load the same amount of beign data from original database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "199f2b2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading benign images: 100%|██████████| 19457/19457 [00:13<00:00, 1433.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "benign count: 19457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "benign_loaded = 0\n",
    "\n",
    "pbar = tqdm(total=malignant_count, desc=\"Loading benign images\")\n",
    "while benign_loaded < malignant_count:\n",
    "    if original_train_metadata.iloc[idx]['target'] == 0:\n",
    "        image_id = original_train_metadata.iloc[idx]['isic_id']\n",
    "        image = original_train_hdf5[image_id][()]\n",
    "        image = np.frombuffer(image, dtype=np.uint8)\n",
    "        image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
    "        image = cv2.resize(image, (128, 128))\n",
    "        image = image / 255\n",
    "        images.append(image)\n",
    "        labels.append(0)\n",
    "        metadata.append(original_train_metadata.iloc[idx])\n",
    "        benign_loaded += 1\n",
    "        pbar.update(1)\n",
    "    idx += 1\n",
    "pbar.close()\n",
    "\n",
    "original_train_hdf5.close()\n",
    "print(f\"benign count: {benign_loaded}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e76c222a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38914\n"
     ]
    }
   ],
   "source": [
    "print(len(images))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188a93fb",
   "metadata": {},
   "source": [
    "### Generate Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a373bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import HDF5Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 70% for training\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    images, labels, test_size=0.3, stratify=labels, random_state=42\n",
    ")\n",
    "\n",
    "# 15% validation, 15% testing\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42\n",
    ")\n",
    "\n",
    "# split metadata\n",
    "metadata_train, metadata_temp = train_test_split(\n",
    "    metadata, test_size=0.3, stratify=labels, random_state=42\n",
    ")\n",
    "metadata_val, metadata_test = train_test_split(\n",
    "    metadata_temp, test_size=0.5, stratify=y_temp, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "385d384e-0605-4008-a2c6-988c0c2ec895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: 27239\n",
      "Validation data: 5837\n",
      "Test data: 5838\n",
      "Metadata Training data: 27239\n",
      "Metadata Validation data: 5837\n",
      "Metadata Test data: 5838\n"
     ]
    }
   ],
   "source": [
    "print(f'Training data: {len(X_train)}')\n",
    "print(f'Validation data: {len(X_val)}')\n",
    "print(f'Test data: {len(X_test)}')\n",
    "print(f'Metadata Training data: {len(metadata_train)}')\n",
    "print(f'Metadata Validation data: {len(metadata_val)}')\n",
    "print(f'Metadata Test data: {len(metadata_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4938933",
   "metadata": {},
   "source": [
    "### Load ISIC Competition Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c3dc199a",
   "metadata": {},
   "outputs": [],
   "source": [
    "isic_test_metadata_path = 'test-metadata.csv'\n",
    "isic_test_metadata = pd.read_csv(isic_test_metadata_path,low_memory=False)\n",
    "isic_test_hdf5_path = 'test-image.hdf5'\n",
    "isic_test_hdf5 = h5py.File(isic_test_hdf5_path, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f65ba078",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 703.70it/s]\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "X_test_isic = []\n",
    "X_test_isic_id = []\n",
    "metadata_test_isic = []\n",
    "for i in tqdm(range(len(isic_test_metadata))):\n",
    "    image_id = isic_test_metadata.iloc[i]['isic_id']\n",
    "    image = isic_test_hdf5[image_id][()]\n",
    "    image = np.frombuffer(image, dtype=np.uint8)\n",
    "    image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
    "    image = cv2.resize(image, (128, 128))\n",
    "    image = image / 255\n",
    "    \n",
    "    # since it does not have labels, we need to manualy ensure it works with the models\n",
    "    if isinstance(image, np.ndarray):\n",
    "        # First ensure it's uint8\n",
    "        if image.dtype != np.uint8:\n",
    "            image = (image * 255).astype(np.uint8)\n",
    "        image = Image.fromarray(image)\n",
    "    X_test_isic.append(image)\n",
    "    metadata_test_isic.append(isic_test_metadata.iloc[i])\n",
    "    X_test_isic_id.append(image_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc78d322",
   "metadata": {},
   "source": [
    "## Load CNN models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2c34365c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b756755",
   "metadata": {},
   "source": [
    "### DenseNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dcc2dff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import densenet121, DenseNet121_Weights\n",
    "from ModelTrainer import Trainer\n",
    "densenet_weights = DenseNet121_Weights.DEFAULT\n",
    "densenet_transform = densenet_weights.transforms()\n",
    "densenet_train_dataset = HDF5Dataset(X_train, y_train, augment=True, transform=densenet_transform)\n",
    "densenet_val_dataset = HDF5Dataset(X_val, y_val, augment=False, transform=densenet_transform)\n",
    "densenet_model = densenet121(weights=densenet_weights)\n",
    "lr = 1e-4\n",
    "num_epochs = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c5f922-ec03-40cd-9e78-b4503c025aa4",
   "metadata": {},
   "source": [
    "#### NOTE!! Still need to run this block below if loading weights!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "93bfeb98-614b-4fca-964c-42f354131128",
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_net_trainer = Trainer(device, densenet_train_dataset, densenet_val_dataset, \"DenseNet121\", densenet_weights, densenet_transform, densenet_model, lr, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c247174f-cfff-4084-b71f-f95c879a1818",
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_net_trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca75e45a-208b-4927-89b3-aa0146aa1259",
   "metadata": {},
   "source": [
    "#### Convert DenseNet's output predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768adf28-0940-439f-88ef-52c3d0f4ddc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "\n",
    "class TorchCNNWrapper(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, model, device='cpu', transform=None, threshold=0.5):\n",
    "        self.model = model.eval().to(device)\n",
    "        self.device = device\n",
    "        self.transform = transform\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def _prepare_image(self, img):\n",
    "        if isinstance(img, np.ndarray):\n",
    "            if img.dtype != np.uint8:\n",
    "                img = (img * 255).astype(np.uint8)\n",
    "            img = Image.fromarray(img)\n",
    "        return self.transform(img).unsqueeze(0).to(self.device)  # Add batch dim\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        self.model.eval()\n",
    "        probs = []\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            for img in tqdm(X, desc=\"Predicting with CNN\"):\n",
    "                img_tensor = self._prepare_image(img)\n",
    "                logits = self.model(img_tensor)\n",
    "                prob = torch.sigmoid(logits).cpu().item()\n",
    "                probs.append([1 - prob, prob])\n",
    "    \n",
    "        return np.array(probs)\n",
    "\n",
    "    def predict(self, X):\n",
    "        probs = self.predict_proba(X)\n",
    "        return (probs[:, 1] >= self.threshold).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea77a71",
   "metadata": {},
   "source": [
    "### Load model if already trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dad0556c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "densenet_model_path = \"DenseNet121_checkpoints/DenseNet121_epoch_20.pth\"\n",
    "densenet_checkpoint = torch.load(densenet_model_path, weights_only=False, map_location=device)\n",
    "densenet_model.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b75513-3e13-4b50-b238-67ecccf2bac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "densenet_model.eval()\n",
    "densenet_wrapper = TorchCNNWrapper(\n",
    "    model=densenet_model,\n",
    "    device=device,\n",
    "    transform=densenet_transform\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629286f0-9079-4b65-adeb-06418eed2963",
   "metadata": {},
   "outputs": [],
   "source": [
    "densenet_wrapper_probas = densenet_wrapper.predict_proba(X_train)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40abe8f4-467a-4b8b-bd81-efeb743af1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "densenet_wrapper_probas[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630f6b59",
   "metadata": {},
   "source": [
    "### Calculate test pAUC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9210c10e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00,  3.82it/s]\n"
     ]
    }
   ],
   "source": [
    "# predict X_test_isic using DenseNet\n",
    "densenet_model.eval()\n",
    "predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for img in tqdm(X_test_isic):\n",
    "        # Apply the transformation (PIL → normalized tensor)\n",
    "        img_tensor = densenet_transform(img).unsqueeze(0).to(device)  # shape: [1, C, H, W]\n",
    "\n",
    "        # Get prediction\n",
    "        logits = densenet_model(img_tensor)\n",
    "        prob = torch.sigmoid(logits).cpu().item()  # probability for class 1 (malignant)\n",
    "        predictions.append(prob)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e198bf5b-0c8e-4f17-b327-758afea144d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.950661241309717e-05, 9.08891342987772e-06, 4.524763880908722e-06]\n"
     ]
    }
   ],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e3856156-da7c-4a20-b47e-507da7e53f97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ISIC_0015657', 'ISIC_0015729', 'ISIC_0015740']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_isic_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fdce6df6-0da8-403b-a5ef-18a2871b2be2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISIC_0015657</td>\n",
       "      <td>0.000050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISIC_0015729</td>\n",
       "      <td>0.000009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISIC_0015740</td>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       image_id    target\n",
       "0  ISIC_0015657  0.000050\n",
       "1  ISIC_0015729  0.000009\n",
       "2  ISIC_0015740  0.000005"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert both to Series or DataFrames\n",
    "densenet_submission = pd.concat([\n",
    "    pd.Series(X_test_isic_id, name=\"image_id\"),\n",
    "    pd.Series(predictions, name=\"target\")\n",
    "], axis=1)\n",
    "\n",
    "densenet_submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe25088-416d-456f-b84d-77a9ca36d32c",
   "metadata": {},
   "source": [
    "## EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4914910f-00ef-48d5-b255-de089719c2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import efficientnet_b3, EfficientNet_B3_Weights\n",
    "efficientnet_weights = EfficientNet_B3_Weights.DEFAULT\n",
    "efficientnet_transform = efficientnet_weights.transforms()\n",
    "efficientnet_train_dataset = HDF5Dataset(X_train, y_train, augment=True, transform=efficientnet_transform)\n",
    "efficientnet_val_dataset = HDF5Dataset(X_val, y_val, augment=False, transform=efficientnet_transform)\n",
    "efficientnet_model = efficientnet_b3(weights=efficientnet_weights)\n",
    "lr = 1e-4\n",
    "num_epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201a9cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "efficientnet_trainer = Trainer(device, efficientnet_train_dataset, efficientnet_val_dataset, \"EfficientNet-B3\", efficientnet_weights, efficientnet_transform, efficientnet_model, lr, num_epochs)\n",
    "efficientnet_trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca1ab4b",
   "metadata": {},
   "source": [
    "### Load EfficientNet Model if already trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad971031",
   "metadata": {},
   "outputs": [],
   "source": [
    "efficientnet_model_path = \"EfficientNet-B3_checkpoints/EfficientNet-B3_epoch_20.pth\"\n",
    "efficientnet_model.load_state_dict(torch.load(efficientnet_model_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb181cd5",
   "metadata": {},
   "source": [
    "## ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f5018a24-9c63-474d-9db9-eb72ac9b43e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mperform/.local/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/mperform/.local/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "\n",
    "resnet_weights = ResNet50_Weights.DEFAULT\n",
    "resnet_transform = resnet_weights.transforms()\n",
    "\n",
    "resnet_train_dataset = HDF5Dataset(X_train, y_train, transform=resnet_transform)\n",
    "resnet_val_dataset = HDF5Dataset(X_val, y_val, transform=resnet_transform)\n",
    "resnet_model = resnet50(pretrained=True)\n",
    "resnet_model.fc = nn.Linear(resnet_model.fc.in_features, 1)\n",
    "\n",
    "lr = 1e-4\n",
    "num_epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a5018e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20: 100%|██████████| 213/213 [01:11<00:00,  2.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Acc = 0.9808, Precision = 0.9986, Recall = 0.9630, F1 = 0.9805, pAUC = 0.1986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/20: 100%|██████████| 213/213 [01:12<00:00,  2.92it/s]\n"
     ]
    }
   ],
   "source": [
    "resnet_trainer = Trainer(device, resnet_train_dataset, resnet_val_dataset, \"ResNet50\", resnet_weights, resnet_transform, resnet_model, lr, num_epochs)\n",
    "resnet_trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9779821f",
   "metadata": {},
   "source": [
    "### Load ResNet50 if already trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de725b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_model_path = \"ResNet50_checkpoints/ResNet50_epoch_20.pth\"\n",
    "resnet_model.load_state_dict(torch.load(resnet_model_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489439a3",
   "metadata": {},
   "source": [
    "## Load Tree based models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1870b68",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b54cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost.callback import EarlyStopping\n",
    "print(xgb.__version__)\n",
    "XGBoost_model = xgb.XGBClassifier(\n",
    "    n_estimators=1000,\n",
    "    learning_rate=0.01,\n",
    "    max_depth=5,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    eval_metric='logloss',\n",
    "    use_label_encoder=False,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c48b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = np.array(metadata)\n",
    "X_metadata_train, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd29991e",
   "metadata": {},
   "outputs": [],
   "source": [
    "XGBoost_model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    # early_stopping_rounds=50,  # <-- now accepted\n",
    "    verbose=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
