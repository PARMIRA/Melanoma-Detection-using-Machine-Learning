{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import h5py\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "import torch\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "#TODO: change this to your own directory\n",
    "# current_dir = \"/Users/thatblue340/Documents/Documents/GitHub/EECS-545-final-project\"\n",
    "current_dir = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vae import CVAE\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading\n",
    "- Load images to train VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 401059 entries, 0 to 401058\n",
      "Data columns (total 55 columns):\n",
      " #   Column                        Non-Null Count   Dtype  \n",
      "---  ------                        --------------   -----  \n",
      " 0   isic_id                       401059 non-null  object \n",
      " 1   target                        401059 non-null  int64  \n",
      " 2   patient_id                    401059 non-null  object \n",
      " 3   age_approx                    398261 non-null  float64\n",
      " 4   sex                           389542 non-null  object \n",
      " 5   anatom_site_general           395303 non-null  object \n",
      " 6   clin_size_long_diam_mm        401059 non-null  float64\n",
      " 7   image_type                    401059 non-null  object \n",
      " 8   tbp_tile_type                 401059 non-null  object \n",
      " 9   tbp_lv_A                      401059 non-null  float64\n",
      " 10  tbp_lv_Aext                   401059 non-null  float64\n",
      " 11  tbp_lv_B                      401059 non-null  float64\n",
      " 12  tbp_lv_Bext                   401059 non-null  float64\n",
      " 13  tbp_lv_C                      401059 non-null  float64\n",
      " 14  tbp_lv_Cext                   401059 non-null  float64\n",
      " 15  tbp_lv_H                      401059 non-null  float64\n",
      " 16  tbp_lv_Hext                   401059 non-null  float64\n",
      " 17  tbp_lv_L                      401059 non-null  float64\n",
      " 18  tbp_lv_Lext                   401059 non-null  float64\n",
      " 19  tbp_lv_areaMM2                401059 non-null  float64\n",
      " 20  tbp_lv_area_perim_ratio       401059 non-null  float64\n",
      " 21  tbp_lv_color_std_mean         401059 non-null  float64\n",
      " 22  tbp_lv_deltaA                 401059 non-null  float64\n",
      " 23  tbp_lv_deltaB                 401059 non-null  float64\n",
      " 24  tbp_lv_deltaL                 401059 non-null  float64\n",
      " 25  tbp_lv_deltaLB                401059 non-null  float64\n",
      " 26  tbp_lv_deltaLBnorm            401059 non-null  float64\n",
      " 27  tbp_lv_eccentricity           401059 non-null  float64\n",
      " 28  tbp_lv_location               401059 non-null  object \n",
      " 29  tbp_lv_location_simple        401059 non-null  object \n",
      " 30  tbp_lv_minorAxisMM            401059 non-null  float64\n",
      " 31  tbp_lv_nevi_confidence        401059 non-null  float64\n",
      " 32  tbp_lv_norm_border            401059 non-null  float64\n",
      " 33  tbp_lv_norm_color             401059 non-null  float64\n",
      " 34  tbp_lv_perimeterMM            401059 non-null  float64\n",
      " 35  tbp_lv_radial_color_std_max   401059 non-null  float64\n",
      " 36  tbp_lv_stdL                   401059 non-null  float64\n",
      " 37  tbp_lv_stdLExt                401059 non-null  float64\n",
      " 38  tbp_lv_symm_2axis             401059 non-null  float64\n",
      " 39  tbp_lv_symm_2axis_angle       401059 non-null  int64  \n",
      " 40  tbp_lv_x                      401059 non-null  float64\n",
      " 41  tbp_lv_y                      401059 non-null  float64\n",
      " 42  tbp_lv_z                      401059 non-null  float64\n",
      " 43  attribution                   401059 non-null  object \n",
      " 44  copyright_license             401059 non-null  object \n",
      " 45  lesion_id                     22058 non-null   object \n",
      " 46  iddx_full                     401059 non-null  object \n",
      " 47  iddx_1                        401059 non-null  object \n",
      " 48  iddx_2                        1068 non-null    object \n",
      " 49  iddx_3                        1065 non-null    object \n",
      " 50  iddx_4                        551 non-null     object \n",
      " 51  iddx_5                        1 non-null       object \n",
      " 52  mel_mitotic_index             53 non-null      object \n",
      " 53  mel_thick_mm                  63 non-null      float64\n",
      " 54  tbp_lv_dnn_lesion_confidence  401059 non-null  float64\n",
      "dtypes: float64(35), int64(2), object(18)\n",
      "memory usage: 168.3+ MB\n"
     ]
    }
   ],
   "source": [
    "train_metadata = pd.read_csv(os.path.join(current_dir,'train-metadata.csv'),low_memory=False)   \n",
    "train_metadata.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3 entries, 0 to 2\n",
      "Data columns (total 44 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   isic_id                      3 non-null      object \n",
      " 1   patient_id                   3 non-null      object \n",
      " 2   age_approx                   3 non-null      float64\n",
      " 3   sex                          3 non-null      object \n",
      " 4   anatom_site_general          3 non-null      object \n",
      " 5   clin_size_long_diam_mm       3 non-null      float64\n",
      " 6   image_type                   3 non-null      object \n",
      " 7   tbp_tile_type                3 non-null      object \n",
      " 8   tbp_lv_A                     3 non-null      float64\n",
      " 9   tbp_lv_Aext                  3 non-null      float64\n",
      " 10  tbp_lv_B                     3 non-null      float64\n",
      " 11  tbp_lv_Bext                  3 non-null      float64\n",
      " 12  tbp_lv_C                     3 non-null      float64\n",
      " 13  tbp_lv_Cext                  3 non-null      float64\n",
      " 14  tbp_lv_H                     3 non-null      float64\n",
      " 15  tbp_lv_Hext                  3 non-null      float64\n",
      " 16  tbp_lv_L                     3 non-null      float64\n",
      " 17  tbp_lv_Lext                  3 non-null      float64\n",
      " 18  tbp_lv_areaMM2               3 non-null      float64\n",
      " 19  tbp_lv_area_perim_ratio      3 non-null      float64\n",
      " 20  tbp_lv_color_std_mean        3 non-null      float64\n",
      " 21  tbp_lv_deltaA                3 non-null      float64\n",
      " 22  tbp_lv_deltaB                3 non-null      float64\n",
      " 23  tbp_lv_deltaL                3 non-null      float64\n",
      " 24  tbp_lv_deltaLB               3 non-null      float64\n",
      " 25  tbp_lv_deltaLBnorm           3 non-null      float64\n",
      " 26  tbp_lv_eccentricity          3 non-null      float64\n",
      " 27  tbp_lv_location              3 non-null      object \n",
      " 28  tbp_lv_location_simple       3 non-null      object \n",
      " 29  tbp_lv_minorAxisMM           3 non-null      float64\n",
      " 30  tbp_lv_nevi_confidence       3 non-null      float64\n",
      " 31  tbp_lv_norm_border           3 non-null      float64\n",
      " 32  tbp_lv_norm_color            3 non-null      float64\n",
      " 33  tbp_lv_perimeterMM           3 non-null      float64\n",
      " 34  tbp_lv_radial_color_std_max  3 non-null      float64\n",
      " 35  tbp_lv_stdL                  3 non-null      float64\n",
      " 36  tbp_lv_stdLExt               3 non-null      float64\n",
      " 37  tbp_lv_symm_2axis            3 non-null      float64\n",
      " 38  tbp_lv_symm_2axis_angle      3 non-null      int64  \n",
      " 39  tbp_lv_x                     3 non-null      float64\n",
      " 40  tbp_lv_y                     3 non-null      float64\n",
      " 41  tbp_lv_z                     3 non-null      float64\n",
      " 42  attribution                  3 non-null      object \n",
      " 43  copyright_license            3 non-null      object \n",
      "dtypes: float64(33), int64(1), object(10)\n",
      "memory usage: 1.2+ KB\n"
     ]
    }
   ],
   "source": [
    "test_metadata = pd.read_csv(os.path.join(current_dir,'test-metadata.csv'),low_memory=False)\n",
    "test_metadata.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_validation_hdf5 = h5py.File(f\"{current_dir}/train-image.hdf5\", 'r')\n",
    "# testing_hdf5 = h5py.File(f\"{current_dir}/test-image.hdf5\", 'r')\n",
    "training_validation_hdf5 = h5py.File(\"train-image.hdf5\", 'r')\n",
    "testing_hdf5 = h5py.File(f\"test-image.hdf5\", 'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess data\n",
    "- Only take the malignant images\n",
    "- Resize them to (128, 128, 3)\n",
    "- Normalize pixel values to [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 401059/401059 [00:09<00:00, 42256.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training images shape: (393, 128, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "# import training images \n",
    "train_images = []\n",
    "for i in tqdm.tqdm(range(len(train_metadata))):\n",
    "    if train_metadata.iloc[i]['target'] == 0: # skip non-target images\n",
    "        continue\n",
    "    image_id = train_metadata.iloc[i]['isic_id']\n",
    "    image = training_validation_hdf5[image_id][()]\n",
    "    image = np.frombuffer(image, dtype=np.uint8)\n",
    "    image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
    "    image = cv2.resize(image, (128, 128))\n",
    "    image = image / 255\n",
    "    train_images.append(image)\n",
    "train_images = np.array(train_images)\n",
    "\n",
    "\n",
    "print(f\"Training images shape: {train_images.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assumes train_images is a NumPy array: (N, 128, 128, 3)\n",
    "os.makedirs(\"augmented_images\", exist_ok=True)\n",
    "\n",
    "augmentation = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation(20),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Apply 5 augmentations per image\n",
    "n_augments = 5\n",
    "\n",
    "for idx, img in enumerate(train_images):\n",
    "    img = (img * 255).astype(\"uint8\")  # convert back to uint8 if needed\n",
    "    for j in range(n_augments):\n",
    "        aug_img = augmentation(img)\n",
    "        save_img = to_pil_image(aug_img)\n",
    "        save_img.save(f\"augmented_images/img_{idx:03}_aug{j:02}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def jigsaw_augment(img, grid_size=4):\n",
    "    h, w, _ = img.shape\n",
    "    patch_h, patch_w = h // grid_size, w // grid_size\n",
    "    patches = []\n",
    "\n",
    "    for i in range(grid_size):\n",
    "        for j in range(grid_size):\n",
    "            patch = img[i*patch_h:(i+1)*patch_h, j*patch_w:(j+1)*patch_w, :]\n",
    "            patches.append(patch)\n",
    "\n",
    "    np.random.shuffle(patches)\n",
    "\n",
    "    new_img = np.zeros_like(img)\n",
    "    idx = 0\n",
    "    for i in range(grid_size):\n",
    "        for j in range(grid_size):\n",
    "            new_img[i*patch_h:(i+1)*patch_h, j*patch_w:(j+1)*patch_w, :] = patches[idx]\n",
    "            idx += 1\n",
    "\n",
    "    return new_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"jigsaw_images\", exist_ok=True)\n",
    "\n",
    "for idx, img in enumerate(train_images):\n",
    "    img_uint8 = (img * 255).astype(np.uint8)\n",
    "    for j in range(3):  # 3 jigsaw variations per image\n",
    "        jigsawed = jigsaw_augment(img_uint8, grid_size=4)\n",
    "        cv2.imwrite(f\"jigsaw_images/img_{idx:03}_jigsaw{j:02}.png\", jigsawed[..., ::-1])  # RGB → BGR"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
